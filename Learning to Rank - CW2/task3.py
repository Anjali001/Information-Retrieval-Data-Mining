# -*- coding: utf-8 -*-
"""IRDM_cw2_part3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1J0My5DaaQEY2fNLPJlQWFSmlS0LWLky2
"""

import pandas as pd
import numpy as np
import string
import matplotlib.pyplot as plt
import seaborn as sns
from nltk.tokenize import RegexpTokenizer
from nltk.corpus import stopwords
import nltk
nltk.download('stopwords')
pd.options.mode.chained_assignment = None
from tqdm import tqdm

from google.colab import drive
drive.mount('/content/drive')

validation_data = pd.read_csv('/content/drive/MyDrive/IRDM Coursework 2/validation_data_cosine.csv',index_col=0)

train_data = pd.read_csv('/content/drive/MyDrive/IRDM Coursework 2/train_data.tsv',sep='\t')
print(train_data.shape)

train_data['relevancy'].value_counts(normalize=True)

def negative_sampling(data,r,k):
  qid_list = np.unique(np.asarray(data['qid']))
  samples = []
  for qid in qid_list:
    pos_temp = data[(data['qid'] == qid) & (data['relevancy'] == 1)]
    neg_temp = data[(data['qid'] == qid) & (data['relevancy'] == 0)]
    if len(pos_temp)<r:
      samples.append(pos_temp)
    else:
      samples.append(pos_temp.sample(n=r, random_state=1))
    if len(neg_temp) < k:
      samples.append(neg_temp)
    else:
      samples.append(neg_temp.sample(n=k, random_state=1))
  new_data = pd.concat(samples)
  return new_data.reset_index(drop=True)

final_train = negative_sampling(train_data,10,20)
final_train = final_train.reset_index(drop=True)

# from imblearn.over_sampling import RandomOverSampler

final_train['relevancy'].value_counts(normalize=True)

def preprocess_single_passage(passage,stop_words=True):
    tokenizer = RegexpTokenizer(r'\w+')
    tok_pass = tokenizer.tokenize(passage)
    tok_pass = [tok for tok in tok_pass if tok.isalpha()]
    tok_pass = [tok.lower() for tok in tok_pass]
    
    if stop_words == True:
        stop_words = stopwords.words('english')
        tokens = [tok for tok in tok_pass if tok not in stop_words]
    else:
        tokens = tok_pass
    return tokens

query_tokens_dict = {}
qid_list, ind_list = np.unique(np.asarray(final_train['qid']),return_index=True)
for qid, ind in tqdm(zip(qid_list,ind_list)):
  query_tokens_dict[qid] = preprocess_single_passage(final_train.loc[ind,'queries'])
final_train.loc[:,'query_tokens'] = final_train['qid'].map(query_tokens_dict)

passage_tokens_dict = {}
pid_list, ind_list = np.unique(np.asarray(final_train['pid']),return_index=True)
for pid, ind in tqdm(zip(pid_list,ind_list)):
  passage_tokens_dict[pid] = preprocess_single_passage(final_train.loc[ind,'passage'])
final_train['passage_tokens'] = final_train['pid'].map(passage_tokens_dict)

from gensim.test.utils import datapath, get_tmpfile
from gensim.models import KeyedVectors
from gensim.scripts.glove2word2vec import glove2word2vec
glove_file = '/content/drive/MyDrive/IRDM Coursework 2/glove.6B.50d.txt'
tmp_file = get_tmpfile("test_word2vec.txt")
_ = glove2word2vec(glove_file, tmp_file)
model = KeyedVectors.load_word2vec_format(tmp_file,binary=False)

def get_embedding(tokens):
  '''
  INPUT
  tokens: a list of tokens
  OUTPUT
  average embedding: a vectorb represents average embedding of the input list of tokens
  '''
  embedding = 0
  nom = len(tokens)
  for token in tokens:
    if token not in model:
      nom -= 1
    else:
      embedding += model[token]
  try:
    return embedding/nom
  except:
    return 0

passage_embedding_dict = {}
pid_list, ind_list = np.unique(np.asarray(final_train['pid']),return_index=True)
for pid,ind in tqdm(zip(pid_list,ind_list)):
  passage_embedding_dict[pid] = get_embedding(final_train.loc[ind,'passage_tokens']) 
final_train['passage_embedding'] = final_train['pid'].map(passage_embedding_dict)

query_embedding_dict = {}
qid_list, ind_list = np.unique(np.asarray(final_train['qid']),return_index=True)
for qid,ind in tqdm(zip(qid_list,ind_list)):
  query_embedding_dict[qid] = get_embedding(final_train.loc[ind,'query_tokens']) 
final_train['query_embedding'] = final_train['qid'].map(query_embedding_dict)

def cosine_similarity(data):
  temp = []
  for i in tqdm(range(len(data))):
    denom = np.dot(data.loc[i,'query_embedding'],data.loc[i,'passage_embedding'])
    nom = np.sqrt(np.square(data.loc[i,'query_embedding']).sum())*np.sqrt(np.square(data.loc[i,'passage_embedding']).sum())
    if nom == 0:
      temp.append(0)
    else:
      temp.append(denom/nom)
  data['cosine_similarity'] = temp
  return data

cosine_similarity(final_train)

final_train['DocLen'] = 0
final_train['queryLen'] = 0
for i, row in final_train.iterrows():
  final_train['DocLen'][i] = len(final_train['passage'][i])
  final_train['queryLen'][i] = len(final_train['queries'][i])

validation_data['DocLen'] = 0
validation_data['queryLen'] = 0
for i, row in validation_data.iterrows():
  validation_data['DocLen'][i] = len(validation_data['passage'][i])
  validation_data['queryLen'][i] = len(validation_data['queries'][i])

final_train.shape

X = final_train[['cosine_similarity', 'DocLen', 'queryLen','qid','relevancy']]

from sklearn.model_selection import train_test_split
Tr,V = train_test_split(X,test_size = 0.2,stratify = final_train['relevancy'])

from xgboost import DMatrix,train,cv
num_of_features = 3
training_data = Tr.sort_values(by=['qid'], ascending=False)

xTr = training_data[['cosine_similarity', 'DocLen', 'queryLen']].values
yTr = training_data['relevancy'].values
QueryCount_Tr = training_data['qid'].value_counts().to_dict() #qid as key and counts as value

Dgroup_Tr = []
qid_list_Tr = []
for idx, row in training_data.iterrows():
  query = row['qid']
  if query in qid_list_Tr:
    continue
  else:
    qid_list_Tr.append(query)
    Dgroup_Tr.append(QueryCount_Tr[query])

V = V.sort_values(by=['qid'], ascending=False)

xV = V[['cosine_similarity', 'DocLen', 'queryLen']].values
yV = V['relevancy'].values
QueryCount_V = V['qid'].value_counts().to_dict() #qid as key and counts as value

Dgroup_V = []
qid_list_V = []
for idx, row in V.iterrows():
  query = row['qid']
  if query in qid_list_V:
    continue
  else:
    qid_list_V.append(query)
    Dgroup_V.append(QueryCount_V[query])

validation_data = validation_data.sort_values(by=['qid'], ascending=False)
xTe = validation_data[['cosine_similarity', 'DocLen', 'queryLen']].values
yTe = validation_data['relevancy'].values
QueryCount_Te = validation_data['qid'].value_counts().to_dict() #qid as key and counts as value

Dgroup_Te = []
qid_list_Te = []
for idx, row in validation_data.iterrows():
  query = row['qid']
  if query in qid_list_Te:
    continue
  else:
    qid_list_Te.append(query)
    Dgroup_Te.append(QueryCount_Te[query])

Tr_dmatrix = DMatrix(data = xTr, label = yTr)
Te_dmatrix = DMatrix(data = xTe, label = yTe)
V_dmatrix = DMatrix(data = xV, label = yV)
Tr_dmatrix.set_group(Dgroup_Tr)
Te_dmatrix.set_group(Dgroup_Te)
V_dmatrix.set_group(Dgroup_V)

params1 = {'objective': 'rank:ndcg', 'eval_metric': 'ndcg', 'eta': 0.0001, 'max_depth': 5}
#eta is learning rate

lambdaRank_model1 = train(params1, Tr_dmatrix, num_boost_round=500,evals=[(V_dmatrix, 'validation')],verbose_eval =100)

params2 = {'objective': 'rank:ndcg', 'eval_metric': 'ndcg', 'eta': 0.001, 'max_depth': 5}
lambdaRank_model2 = train(params2, Tr_dmatrix, num_boost_round=500,evals=[(V_dmatrix, 'validation')],verbose_eval =100)

params3 = {'objective': 'rank:ndcg', 'eval_metric': 'ndcg', 'eta': 0.01, 'max_depth': 5}
lambdaRank_model3 = train(params3, Tr_dmatrix, num_boost_round=500,evals=[(V_dmatrix, 'validation')],verbose_eval =100)

params4 = {'objective': 'rank:ndcg', 'eval_metric': 'ndcg', 'eta': 0.1, 'max_depth': 5}
lambdaRank_model4 = train(params4, Tr_dmatrix, num_boost_round=500,evals=[(V_dmatrix, 'validation')],verbose_eval =100)

params5 = {'objective': 'rank:ndcg', 'eval_metric': 'ndcg', 'eta': 1, 'max_depth': 5}
lambdaRank_model5 = train(params5, Tr_dmatrix, num_boost_round=500,evals=[(V_dmatrix, 'validation')],verbose_eval =100)

params6 = {'objective': 'rank:ndcg', 'eval_metric': 'ndcg', 'eta': 0, 'max_depth': 5}
lambdaRank_model6 = train(params6, Tr_dmatrix, num_boost_round=500,evals=[(V_dmatrix, 'validation')],verbose_eval =100)

params7 = {'objective': 'rank:ndcg', 'eval_metric': 'ndcg', 'eta': 0.01, 'max_depth': 8}
lambdaRank_model7 = train(params7, Tr_dmatrix, num_boost_round=500,evals=[(V_dmatrix, 'validation')],verbose_eval =100)

params8 = {'objective': 'rank:ndcg', 'eval_metric': 'ndcg', 'eta': 0.01, 'max_depth': 12}
lambdaRank_model8 = train(params8, Tr_dmatrix, num_boost_round=500,evals=[(V_dmatrix, 'validation')],verbose_eval =100)

params9 = {'objective': 'rank:ndcg', 'eval_metric': 'ndcg', 'eta': 0.01}
lambdaRank_model9 = train(params9, Tr_dmatrix, num_boost_round=500,evals=[(V_dmatrix, 'validation')],verbose_eval =100)

# import xgboost as xgb
# model = xgb.XGBRanker(
#     tree_method='exact',
#     booster='gbtree',
#     objective='rank:ndcg',
#     random_state=42,
#     learning_rate=0.06,
#     max_depth=5,
#     n_estimators=700,
#     subsample=0.75,
#     min_child_weight=0.06
#     )

# model.fit(xTr, yTr, group=Dgroup_Tr, verbose=True,eval_set= xV,eval_group =Dgroup_V )

# import scipy.stats as stats
# param_dist = {'n_estimators': stats.randint(40, 1000),
#               'learning_rate': stats.uniform(0.01, 0.59),
#               'subsample': stats.uniform(0.3, 0.6),
#               'max_depth': [3, 4, 5, 6, 7, 8, 9],
#               'colsample_bytree': stats.uniform(0.5, 0.4),
#               'min_child_weight': [0.05, 0.1, 0.02]
#               }

# from sklearn.model_selection import RandomizedSearchCV
# import sklearn
# scoring = sklearn.metrics.make_scorer(sklearn.metrics.ndcg_score, greater_is_better=True)
# clf = RandomizedSearchCV(model,
#                          param_distributions=param_dist,
#                          cv=2,
#                          n_iter=5,  
#                          scoring= scoring,
#                          error_score=0,
#                          verbose=3,
#                          n_jobs=-1)
# xyz = clf.fit(xTr,yTr,fit_params={"model__groups": Dgroup_Tr})

y_pred = lambdaRank_model3.predict(Te_dmatrix)
y_pred.shape
#validation_data.shape

validation_data['score'] = y_pred
validation_data.head()

validation_data['LM_rank'] = validation_data.groupby('qid')['score'].rank(method='first',ascending=False).astype('int')

trial_data = validation_data[['qid','pid','LM_rank','score']]

trial_data = trial_data.reset_index(drop=True)

LM_dict = {}
qid_list = trial_data['qid'].unique()
for qid in qid_list:
    top_ones = trial_data[trial_data['qid'] == qid]
    top_ones = top_ones.reset_index(drop=True)
    top_ones = top_ones.sort_values(by=['LM_rank'])
    LM_dict[qid] = top_ones[:100]

f = open("LM.txt", "w")
for lr_df in LM_dict.values():
    for i, data in lr_df.iterrows():
        qid = str(data['qid'].astype(int))
        pid = str(data['pid'].astype(int))
        score = str(data['score'])
        rank = str(data['LM_rank'].astype(int))
        f.write(qid + "," + "A2" + "," + pid + "," + rank + "," + score + "," + "LM" + "\n")
f.close()

def average_precision_calc(df,retrieved,score,rank):
    average_precision = 0
    qid_list = np.unique(np.asarray(df['qid']))
    ranked_passages = df[df[rank] <= retrieved]

    relevant_passage = ranked_passages[ranked_passages['relevancy'] != 0]
    relevant_passage['rank'] = relevant_passage.groupby('qid')[score].rank(method = 'first',ascending=False)

    for qid in qid_list:
        temp = relevant_passage[relevant_passage['qid'] == qid]
        temp['rank'] = temp['rank']/temp[rank]
        if len(temp) == 0:
            average_precision += 0
        else:
            average_precision += sum(temp['rank'])/len(temp)

    average_precision = average_precision/len(qid_list)
    return average_precision

average_precision_LM = average_precision_calc(validation_data,100,'score','LM_rank')

average_precision_LM

def NDCG_calc(df,retrieved, rank):

    all_DCG = 0
    relevant_passage = df[df['relevancy'] != 0]
    relevant_passage_retrived = relevant_passage[relevant_passage[rank] <= retrieved]

    qid_list = np.unique(np.asarray(df['qid']))

    for qid in qid_list:
        temp = relevant_passage[relevant_passage['qid'] == qid]
        DCG = sum(1/np.log2(np.asarray(temp[rank])+1))
        optDCG = sum(1/np.log2(np.arange(1,len(temp)+1)+1))
        all_DCG += DCG/optDCG
    all_DCG = all_DCG/len(qid_list)

    return all_DCG

NDCG_LM = NDCG_calc(validation_data,100,'LM_rank')

NDCG_LM